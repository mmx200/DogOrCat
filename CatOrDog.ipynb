{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤一：导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 定义函数来加载train，test和validation数据集\n",
    "def load_dataset(path):\n",
    "    list = os.listdir(path)\n",
    "    files = []\n",
    "    targets = []\n",
    "    for i in range(0,len(list)):\n",
    "        filepath = os.path.join(path,list[i])\n",
    "        if os.path.isfile(filepath):\n",
    "            files.append(filepath)\n",
    "            if(list[i].find('dog')>=0):\n",
    "                targets.append([1,0])\n",
    "            else:\n",
    "                targets.append([0,1])\n",
    "    return files,targets\n",
    "\n",
    "\n",
    "# 加载train，valid数据集\n",
    "#train_files, train_targets = load_dataset('data/train')\n",
    "#valid_files, valid_targets = load_dataset('data/valid')\n",
    "\n",
    "\n",
    "\n",
    "# 将数据集拆分成训练集，校验集,测试集\n",
    "#tmp_files, test_files, tmp_targets, test_targets = train_test_split(data_files, data_targets, test_size = 0.2,random_state=10)\n",
    "#train_files, valid_files, train_targets, valid_targets = train_test_split(tmp_files, tmp_targets, test_size = 0.25,random_state=10)\n",
    "\n",
    "# 打印数据统计描述\n",
    "#a = np.array(train_targets)\n",
    "#print('训练集中有{}只狗，{}只猫'.format(sum(a[:,0]),sum(a[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤二：数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # 用PIL加载RGB图像为PIL.Image.Image类型\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # 将PIL.Image.Image类型转化为格式为(224, 224, 3)的3维张量\n",
    "    x = image.img_to_array(img)\n",
    "    # 将3维张量转化为格式为(1, 224, 224, 3)的4维张量并返回\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤三：使用迁移训练\n",
    "### 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#图片数组生成器\n",
    "def generate_arrays_from_path(files):\n",
    "    while 1:\n",
    "        for i in range(0,len(files)):\n",
    "            X = preprocess_input(path_to_tensor(files[i]).astype('float32')/255)\n",
    "                \n",
    "            yield X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDataGen = image.ImageDataGenerator(\n",
    "    rescale = 1.0/255,\n",
    "#    rotation_range=30,\n",
    "#    width_shift_range=0.3,\n",
    "#    height_shift_range=0.3,\n",
    "#    zoom_range=0.5,\n",
    "#    channel_shift_range=10,\n",
    "#    preprocessing_function = preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('train2/cat.0.jpg') \n",
    "x = image.img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "for batch in imageDataGen.flow(x,batch_size=1,save_to_dir='preview',save_prefix='test3', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # 否则生成器会退出循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = imageDataGen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode=None,\n",
    "        shuffle=False) \n",
    "\n",
    "valid_generator = imageDataGen.flow_from_directory(\n",
    "        'data/valid',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode=None,\n",
    "        shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "'''\n",
    "bottleneck_features_train = model.predict_generator(generate_arrays_from_path(train_files),15000,verbose=2)\n",
    "bottleneck_features_valid = model.predict_generator(generate_arrays_from_path(valid_files),5000,verbose=2)\n",
    "bottleneck_features_test = model.predict_generator(generate_arrays_from_path(test_files),5000,verbose=2)\n",
    "'''\n",
    "\n",
    "bottleneck_features_train = model.predict_generator(train_generator,1000)\n",
    "bottleneck_features_valid = model.predict_generator(valid_generator,400)\n",
    "#bottleneck_features_test = model.predict_generator(generate_arrays_from_path(test_files),300,verbose=2)\n",
    "\n",
    "np.save(open('bottleneck_features_train.npy','wb'),bottleneck_features_train)\n",
    "np.save(open('bottleneck_features_valid.npy','wb'),bottleneck_features_valid)\n",
    "#np.save(open('bottleneck_features_test.npy','wb'),bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步骤四：训练模型\n",
    "### 搭建VGG迁移模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_VGG16 = np.load('bottleneck_features_train.npy')\n",
    "valid_VGG16 = np.load('bottleneck_features_valid.npy')\n",
    "#test_VGG16 = np.load('bottleneck_features_test.npy')\n",
    "\n",
    "\n",
    "train_targets = np.array([0,1] * 500 + [1,0] * 500)\n",
    "valid_targets = np.array([0,1] * 200 + [1,0] * 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dropout(0.5))\n",
    "VGG16_model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "## 训练模型\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG16.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, np.array(train_targets), \n",
    "          validation_data=(valid_VGG16, np.array(valid_targets)),\n",
    "          epochs=10, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载具有最好验证loss的模型\n",
    "\n",
    "VGG16_model.load_weights('saved_models/weights.best.VGG16.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dogorcat(file):\n",
    "    bnf = model.predict(preprocess_input(path_to_tensor(file).astype('float32')/255))\n",
    "    predict = VGG16_model.predict(bnf)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt       \n",
    "\n",
    "\n",
    "img_path = os.path.join('test/128.jpg')\n",
    "img = mpimg.imread(img_path,0)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "predict = dogorcat(img_path)\n",
    "dog_ratio = predict[0][0]*100\n",
    "cat_ratio = predict[0][1]*100\n",
    "print('狗：%.2f%%'% dog_ratio)\n",
    "print('猫：%.2f%%'% cat_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 48.67%\n"
     ]
    }
   ],
   "source": [
    "# 获取测试数据集中每一个图像所预测的狗品种的index\n",
    "dogorcat_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature,axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# 报告测试准确率\n",
    "test_accuracy = 100*np.sum(np.array(dogorcat_predictions)==np.argmax(test_targets[:300], axis=1))/len(dogorcat_predictions)\n",
    "print('Test accuracy: %.2f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "list = os.listdir('test')\n",
    "f, axs = plt.subplots(2,4,figsize=(15,8))\n",
    "for c in range(2):\n",
    "    for r in range(4):\n",
    "        img_path = os.path.join('test',list[c*2+r])\n",
    "        predict = dogorcat(img_path)\n",
    "        img = mpimg.imread(img_path,0)\n",
    "        axs[c][r].set_xticks([])\n",
    "        axs[c][r].set_yticks([])\n",
    "        axs[c][r].imshow(img)\n",
    "        if(np.argmax(predict[0])==0):\n",
    "            s = 'dog' \n",
    "        else:\n",
    "            s = 'cat'\n",
    "        s= '%s:%.2f%%' % (s,max(predict[0])*100)\n",
    "        axs[c][r].set_title(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = VGG16_model.evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
